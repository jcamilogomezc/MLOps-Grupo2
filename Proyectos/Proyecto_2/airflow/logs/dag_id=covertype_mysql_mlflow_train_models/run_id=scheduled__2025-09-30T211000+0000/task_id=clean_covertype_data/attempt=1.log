{"timestamp":"2025-09-30T21:15:54.383649","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-30T21:15:54.385038","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/ETL_Training.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-30T21:15:57.603201","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `get` on Connection from sdk(`airflow.sdk.Connection`) instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-09-30T21:15:57.831527","level":"warning","event":"empty cryptography key - values will not be stored encrypted.","logger":"airflow.models.crypto"}
{"timestamp":"2025-09-30T21:15:57.834226","level":"info","event":"Connection Retrieved 'mysql_trn'","logger":"airflow.hooks.base"}
{"timestamp":"2025-09-30T21:15:57.834518","level":"warning","event":"This setter is for backward compatibility and should not be used.\nSince the introduction of connection property, the providers listed below breaks due to assigning value to self.connection in their __init__ method.\n* apache-airflow-providers-mysql<5.7.1\n* apache-airflow-providers-elasticsearch<5.5.1\n* apache-airflow-providers-postgres<5.13.0","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook"}
{"timestamp":"2025-09-30T21:15:57.876569","level":"warning","event":"/opt/airflow/dags/ETL_Training.py:139: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  df = pd.read_sql(\"\"\"\n","logger":"py.warnings"}
{"timestamp":"2025-09-30T21:15:57.883618Z","level":"info","event":"[PREPROCESS] Raw data loaded: 456 rows","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-30T21:15:57.912462Z","level":"info","event":"[PREPROCESS] Removed 12 outliers from horizontal_distance_to_roadways","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-30T21:15:57.915785Z","level":"info","event":"[PREPROCESS] Removed 2 outliers from horizontal_distance_to_fire_points","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-30T21:15:57.916444Z","level":"info","event":"[PREPROCESS] Outlier removal: 456 -> 442 rows (14 removed)","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-30T21:15:57.929647Z","level":"info","event":"[PREPROCESS] Final data quality summary:","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-30T21:15:57.930303Z","level":"info","event":"  - Total rows: 442","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-30T21:15:57.931605Z","level":"info","event":"  - Missing values: 0","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-30T21:15:57.934773Z","level":"info","event":"  - Duplicate rows: 22","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-30T21:15:57.944284Z","level":"info","event":"[PREPROCESS] Removed 0 duplicate rows","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-30T21:15:58.294561","level":"info","event":"Done loading. Loaded a total of 420 rows into covertype_clean","logger":"airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook"}
{"timestamp":"2025-09-30T21:15:58.295689Z","level":"info","event":"[PREPROCESS] Clean rows inserted: 420","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-30T21:15:58.296248","level":"info","event":"Done. Returned value was: Data cleaning completed. 420 clean records processed.","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-09-30T21:15:58.296667","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('01999c7b-0e59-7d3d-801b-ce3c5c2c744f'), task_id='clean_covertype_data', dag_id='covertype_mysql_mlflow_train_models', run_id='scheduled__2025-09-30T21:10:00+00:00', try_number=1, map_index=-1, hostname='0154c95c6bde', context_carrier={}, task=<Task(PythonOperator): clean_covertype_data>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=0, start_date=datetime.datetime(2025, 9, 30, 21, 15, 54, 54954, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None, log_url='http://localhost:8080/dags/covertype_mysql_mlflow_train_models/runs/scheduled__2025-09-30T21%3A10%3A00%2B00%3A00/tasks/clean_covertype_data?try_number=1')","logger":"task"}
